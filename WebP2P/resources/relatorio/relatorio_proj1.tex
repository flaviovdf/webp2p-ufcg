\documentclass[a4paper,12pt,titlepage,fullpage]{report}

\usepackage{xspace}
\usepackage{graphicx,url}
\usepackage[brazil]{babel}
\usepackage[latin1]{inputenc}

%opening
\title{Monografia de Conclusão de Curso \\ \textit{Projeto WebP2P}}
\author{Flavio V. D. de Figueiredo \and Flávio Roberto Santos \and João Arthur Brunet Monteiro}

%margins
%margens superior=3,0cm, inferior=2,0cm, esquerda e direita=2,5cm
%\oddsidemargin 2.5cm
%\evensidemargin 2.5cm
%\topmargin 3.0cm

\begin{document}

\maketitle

\tableofcontents

\listoffigures

\chapter{Introdução}
Desde o surgimento da Internet, a disponibilização de conteúdo vem sendo utilizada em grande escala, tornando-a cada vez mais popular. Essa popularidade é diretamente responsável pela enorme procura por informações pelos usuários, o que aumenta o número de acessos aos provedores de conteúdo. A maioria das soluções existentes que disponibilizam conteúdo (páginas web) são centralizadas e acabam sendo o gargalo em momentos em que o número de acessos é elevado. Exemplos dessas soluções são o Apache (http://httpd.apache.org) e o AOLServer (http://www.aolserver.com). Soluções como estas não são facilmente configuráveis por usuários domésticos e algumas outras da mesma natureza são pagas. Em compensação, estes usuários podem usar serviços como o GooglePages (http://pages.google.com) que lhes oferecem espaço para armazenamento na web gratuitamente.

Já foi analisado em outros trabalhos \cite{perucao} que as soluções descritas acima não são adequadas para alguns sites em determinados momentos. Um exemplo deste cenário é o servidor responsável por disponibilizar o conteúdo do resultado de um concurso. O número de acessos no momento da divulgação atinge um estado no qual o site não suporta todas as requisições, tornando o conteúdo indisponível no momento. Isso traz problemas tanto para os usuários, que não conseguem acessar o conteúdo, como também para o administrador, que pode vir a sofrer prejuízos financeiros e/ou reputacionais. A indisponibilidade do conteúdo, nestes casos, normalmente ocorre em decorrência do grande número de acessos a um único servidor. Algumas empresas adotam a compra de várias máquinas para resolver o problema de indisponibilidade. Essas máquinas respondem por um mesmo endereço, balanceando assim a carga(número de acessos ao servidor). No entanto, esta solução não é viável para pequenas empresas ou ou instituições que não possuem recursos para investir em máquinas novas.

A necessidade de manter disponíveis conteúdos em momentos de pico é extremamente importante para a credibilidade de um servidor. Provedores de conteúdo necessitam mantlo disponível o maior tempo possível afim de aumentar o número de clientes o tempo em que o cliente navega pelo site. Contratos entre servidores e empresas interessadas em disponibilizar conteúdo, por muitas vezes, são feitos levando em consideração o tempo de disponibilidade da informação. Neste cenário, indisponibilidade de acesso ao conteúdo se traduzem em prejuízo para o provedor que hospeda a informação, por não ter cumprido o contrato, e para a empresa interessada em disponibilizar a informação, por não ter o seu produto exposto.

Este trabalho tem por objetivo prover uma solução para a indisponibilidade temporária de conteúdo dos servidores web. A nossa solução visa balancear a carga dos servidores sobrecarregados fazendo uso de uma rede peer-to-peer de servidores web onde o conteúdo é distribuído entre os peers. Com a replicacão e distribuição do conteúdo, requisições que são enviadas a um servidor sobrecarregado são redirecionadas para outro servidor que contém um replica do conteúdo requisitado. Desta maneira, o serviço não fica indisponível para o cliente. Além disso, o servidor sobrecarregado tem oportunidade de se reestabelecer, uma vez que as requisições que chegam a ele, enquanto está sobrecarregado, são redirecionadas a outros servidores. À nossa solução demos o nome de WebP2P, uma alusão à servidores web e sistemas peer-to-perr.

WebP2P trata-se de uma solução onde vários servidores cooperam entre si de forma a manter seus conteúdos acessíveis ao usuário. É uma alternativa barata em relação à compra de outras máquinas para balancear a carga que chega ao servidor web. Para o administrador de um servidor web, basta apenas entrar na rede WebP2P para que o seu conteúdo seja replicado entre os outros servidores da rede. Quando for detectado que este servidor está sobrecarregado, o nosso sistema toma as decisões necessárias para redirecionar as requisições direcionadas ao servidor para outros da rede, tornando disponível em outro servidor web o conteúdo requisitado. O balanceamento de carga é totalmente transparente ao usuário de um navegador.

Apresentamos neste documento uma solução peer-to-peer para a indisponibilidade temporária de conteúdo nos servidores web. Na seção ...

% \section{Cronograma}
% 
% Nosso plano de projeto é analisar as solução existentes e propor uma alternativa distribuída para solucionar o problema descrito acima. Nossa solução é baseada na distribuição do conteúdo de um site entre diversos hóspedes em uma rede sobreposta Peer-to-Peer (P2P), assim acreditamos que será possível balancear a banda necessária para um site entre os diversos hóspedes e aumentar a disponibilidade do site. O projeto foi dividido em duas etapas:
% 
% \vspace{1em}
% 
% Na Primeira iremos:
% \begin{enumerate}
% % 	\item Fazer análise experimental das soluções existentes;
% 	\item Levantar problemas das soluções com base na etapa de análise;
% 	\item Gerar um documento com uma arquitetura proposta;
% 	\item Implementar um protótipo inicial da solução distribuída.
% \end{enumerate}
% 
% 
% Na Segunda iremos:
% \begin{enumerate}
% 	\item Concluir implementação da solução distribuída;
% 	\item Fazer uma avaliação da solução proposta;
% 	\item Fazer um comparativo entre as soluções existentes e a solução proposta;
% 	\item Gerar um documento com os resultados obtidos em todas as etapas.
% \end{enumerate}
% 

\chapter{Trabalhos Relacionados}

Nesta seção apresentaremos trabalhos relacionados ao WebP2P. Foram estudadas tecnologias de distribuição e busca de conteúdo, além de servidores web descentralizados.

\section{BitTorrent}

O \textit{BitTorrent}\cite{bittorrent-cohen} é um protocolo criado para distribuir conteúdo em grande escala. Trata-se de uma alternativa distribuída ao modelo clássico de cliente-servidor, onde tínhamos apenas o servidor centralizado provendo o arquivo para um conjunto de usuários. Essa arquitetura centralizada acarreta em uma série de problemas de performance: além de a banda do servidor ser limitada e dividida entre os consumidores de arquivos, ele torna-se um ponto único de falhas.

Uma das propostas do protocolo é justamente de utilizar a banda dos consumidores de conteúdo para ajudar no andamento das transferências. Os clientes começam a obter partes de arquivos de outros clientes, que passam a agir também como servidores. O comportamento colaborativo é reforçado por uma rede de favores, onde quem doa aumenta suas chances de receber mais.

Quanto mais consumidores interessados em um determinado arquivo disponível em um torrent, maior será a contribuição entre os mesmos e maiores serão as taxas de transferência\cite{bitcrowds-adar}. No entanto, o \textit{BitTorrent} tem uma peculiaridade: atrasos na conclusão de uma transferência em um torrent são aceitáveis. Diferentemente de uma distribuição de conteúdo como páginas web, onde o cliente faz uma requisição e não está disposto a esperar muito por uma resposta.

\section{NodeWiz}

\textit{NodeWiz}\cite{nodewiz-sujoy} é um Grid Information Service (GIS) escalável que permite o processamento eficiente e distribuído de buscas multi-atributo por faixas de valores. Isso é feito agregando-se diretórios de serviços individuais em um sistema P2P. Um GIS pode ser visto com um diretório onde provedores de serviço publicam anúncios e onde usuários submetem buscas. No \textit{NodeWiz}, o GIS é implementado por um conjunto de nós (peers) que armazenam anúncios dos provedores de serviço e respondem às buscas dos clientes.

Buscas no \textit{NodeWiz} podem especificar valores para qualquer número de atributos e, além disso, podem especificar faixas de valores para esses atributos. Como exemplo, em um grid que provê CPU como serviço, um cliente pode especificar uma busca que requer uma máquina Linux com no mínimo 1024Mbytes de memória e baixa carga da seguinte maneira: $OS = linux \wedge Mem \leq 1024 \wedge Carga \leq 0.2$.

Na arquitetura do \textit{NodeWiz}, os peers são entidades do GIS e não devem ser confundidos com os nós servidores que são mantidos pelos provedores de serviço onde está hospedado o serviço da aplicação. Clientes e provedores de serviço são vistos como usuários do sistema. Quando um usuário quer fazer uma operação (buscas ou anúncios) submete essa operação para algum peer que ele conhece no sistema, esse peer, digamos recipiente, é o encarregado de rotear a mensagem ao peer apropriado, digamos alvo.

A estrutura do substrato P2P no \textit{NodeWiz} é baseada em árvore, mais especificamente em uma \textit{KD-Tree}\footnote{K-D Tree (K Dimensional Tree) é uma Árvore Binária de Pesquisa (BST) que permite um eficiente processamento de chaves multidimencionais. A Árvore K-D difere da Árvore Binária de Pesquisa (BST) onde cada nível da árvore K-D se ramifica baseada numa pesquisa de chave para o nível, chamado discriminador. \cite{kd-tree}}. Essa abordagem foi uma solução para que o GIS fosse escalável e suportasse buscas multi-atributo por faixas de valores.

Peers que recebem muitas requisições tornam-se sobrecarregados. O \textit{NodeWiz} permite qualquer peer que esteja sobrecarregado, dividir essa carga com peers menos sobrecarregados e assim manter o balanceamento da mesma.

\textit{NodeWiz} se encaixa no escopo da nossa solução de maneira a prover um mecanismo de busca eficiente do conteúdo distribuído. Os peers do \textit{NodeWiz} seriam os servidores web da overlay formada pelo WebP2P. Estes conteriam informações de qual servidor detêm o conteúdo procurado.

\section{Bamboo}

Tabelas hash são estruturas de dados que mapeam chaves $k$ para valores $v$. Em sistemas distribuídos o conceito de Distributed Hash Tables (DHT) tem funcionalidade similar, mas o conjunto de valores é distribuído pela rede. Esta distribuição serve para que que o sistema se torne escalável e tolerante a falhas. Caso a tabela fosse armazenda em um único nó (ou pequeno conjunto), na presença de falhas não seria possível recuperar os valores, este pequeno conjunto seria sobrecarregado de buscas em momentos de alta demanda.

DHTs têm um design descentralizado onde um conjunto de chaves (dentro de um espaço possível bem definido) devem ser mapeadas em cada nodo do sistema. Quando uma busca não pode ser resolvida localmente por um nodo a mensagem é roteada para outro nodo do sistema. Muitas implementações de DHTs possuem esquemas de roteamento eficientes, geralmente com uma complexidade em $O(log N)$ onde N é o número de nodos da rede, ou seja escalável com o crescimento de nodos.

O \textit{OpenDHT}~\cite{bamboo:usenix04} é uma implementação que segue estes princípios, seu design é baseado em outra implementação de DHTs, \textit{Pastry}~\cite{past01}. Neste design estabelece-se em cada nodo tabelas de roteamento com identificadores e endereços IP  de uma porção de nodos do sistema, por exemplo:

\begin{figure}[htbp]
\centering
\includegraphics[width=5cm]{img/tabela2.png}
\caption{Tabela de Roteamento do \textit{OpenDHT}}
\label{fig:dht-tabela de roteamento}
\end{figure}

O \textit{Leaf-set} de um nodo é formado por um conjunto dos nodos com \textit{id} imediatamente maiores e menores que o \textit{id} do próprio.

As entradas da tabela de roteamento são criadas de modo que as entradas da linha N compartilham um prefixo de tamanho N com o nodo que mantém a tabela. Sendo assim temos $\log_{2^b} N$ linhas cada uma com $2^b - 1$ colunas.

O \textit{Neighborhood-set} é feito por nodos que são próximos ao nodo em questão, uma métrica de proximidade pode ser baseada no endereço IP dos nodos.

Dado que já conhecemos as estruturas de dados mantidas por cada nodo, é importante saber os algoritmos responsáveis por manter o roteamento em $O(log N)$. Tanto em \textit{Pastry} como em \textit{OpenDHT} funcionam da seguinte forma:

\begin{itemize}
	\item Para cada busca que chega em um nodo é verificada a sua chave K.
	\item Se K está contida no intervalo do \textit{leaf-set} o pedido é repassado diretamente para o nodo responsável, ou seja foi resolvida em apenas um passo.
	\item Caso a chave K não esteja contida no \textit{leaf-set} busca-se na tabela de roteamento um nodo que compartilhe um id de um ou mais dígitos com a chave, e então o pedido é repassado para este nodo.
	\item É possível que a entrada escolhida no passo anterior não esteja disponível ou acessível então é escolhido um nodo que no mínimo seja mais próximo da chave K do que o nodo que está fazendo o roteamento.
\end{itemize}


As características do design que garantem roteamento em $O(log N)$ estão principalmente na forma que a tabela de roteamento é montada e no passo 3 descrito acima. Como em cada passo do roteamento o conjunto de nodos que compartilham o mesmo prefixo é reduzido por um fator de $2^b$ garante-se  que chega-se em qualquer nodo com $\log_{2^b} N$ passos (desde que não ocorram falhas simultâneas em mais que $L/2$ vizinhos, onde $L$ é o tamanho do \textit{leaf-set}).

Como dissemos o design do \textit{OpenDHT} é inspirado em \textit{Pastry}, na verdade seria mais correto dizer que os dois têm o mesmo design. Uma pergunta pode ocorrer: se o design é igual porque foi feito um clone?

A resposta é direta, a implementação de Pastry não funcionava. Quando o deploy era feito em ambientes reais, onde possivelmente existiam faltas não esperadas, o desempenho do \textit{Pastry} era pior do que o esperado. Em~\cite{bamboo:usenix04} é demonstrado que a causa dos problemas que acontecem em outras DHTs como \textit{Pastry}, \textit{CAN}~\cite{can:sigcomm01} e \textit{Chord}~\cite{chord:sigccomm01} é o Churn, característica comum em sistemas P2P.

Basicamente o que acontece é que em redes congestionadas a entrada de nodos e a recuperação após a saída no sistema era feita de forma imediata e acarretava o aumento de uso de banda o que congestionava mais ainda a rede e acarretava falhas que gerariam mais tráfego para serem corrigidas entrando num círculo vicioso até um ponto em que praticamente não era mais possível usar a DHT.

\begin{figure}[htbp]
\centering
\includegraphics[width=5cm]{img/graphChurn.png}
\caption{Porcentagem de lookups que retornam algum resultado (possivelmente incorreto)}
\label{fig:graph-churn}
\end{figure}

A alternativa usada na implementação do \textit{OpenDHT} foi um esquema de manutenção da rede de forma periódica, ou seja, o tráfico gerado na rede física para manter a rede overlay consistente (tanto para entrada de novos nodos como para recuperação após saída) é proporcional apenas ao número de nodos na rede, ou seja, diferente da implementação anterior de \textit{Pastry} o perigo de derrubar uma rede já congestionada por aumento de banda consumida pelos algoritmos de manutenção de consistência é bem menor.

\section{Coral Content Distribution Network}

A meta do projeto \textit{Coral Content Distribution Network (CoralCDN)}~\cite{coral} é bem parecida com a do WebP2P. No CoralCDN, uma rede P2P é utilizada para disponibilizar caches de conteúdo web. Com este, sites que sofrem sobrecarga podem evitar este problema, pois o acesso ao conteúdo do site pode ser feito através de um dos vários caches mantidos na rede.

O projeto aparenta ser bem maduro e já está disponível para uso gratuítamente. Os nós que compõem a overlay estão rodando no PlanetLab.\footnote{PlanetLab é um laboratório virtual composto de centenas de máquinas na Internet. Para mais informações acesse http://www.planet-lab.org.}

Clientes utilizam o CoralCDN anexando \textit{.nyud.net} a URL de um conteúdo Web. Servidores de conteúdo podem também fazer uso do Coral anexando a mesma URL nos seus links. Abaixo segue uma explicação de como funciona o CoralCDN.

\begin{enumerate}
	\item Um cliente envia um pedido DNS para uma URL com \textit{.nyud.net} anexado a mesma, \textit{e.g. www.x.com.nyud.net}, para o seu resolvedor local.
	
	\item O resolvedor tenta localizar o host usando o DNS do Coral CDN (\textit{dnssrv}), isto deviado ao \textit{.nyud.net} anexado a url.
	
	\item Ao receber o pedido o \textit{dnssrv} calcula o Round Trip Time (RTT) entre si mesmo e o cliente.
	
	\item Com base no RTT o \textit{dnssrv} procura na overlay Coral por proxies perto do cliente.
	
	\item O \textit{dnssrv} responde com os proxies mais próximos do cliente (baseado no RTT), ou um conjunto randomico caso os mais próximos não possam ser resolvidos.
	
	\item O resolvedor do cliente retorna o endereço de um dos proxies definido no passo anterior.
	
	\item O cliente pede o conteúdo para o proxy. Caso este tenha uma cópia do conteúdo esta é retornada, caso contrário o próximo passo é executado.
	
	\item O proxy procura por um cache na overlay.
	
	\item Caso seja encontrado um cache o proxy copia este e retorna para o cliente, caso contrário o conteúdo é retornado da Internet.
	
	\item O proxy avisa a overlay que agora tem uma cópia do conteúdo.
\end{enumerate}

Para as ações de indexação (ex: busca e armazenamento) uma DHT é utilizada, esta DHT tem a propriedade de ser ``sloppy'', sendo assim chamada de Distributed Sloppy Hash Table (DSHT). Em uma DSHT os valores para uma determinada chave podem ser armazenadas e recuperadas em diversos nós. Desta forma, uma distribuição de carga é feita na rede.

O projeto aparentemente é bem maduro e tem metas muito parecidas com as do WebP2P. Tentativas de utilizar o sistema não foram bem sucedidas. Acreditamos que o motivo está relacionado à reestruturação do PlanetLab que estava ocorrendo durante a escrita deste relatório.

Os experimentos feitos no artigo~\cite{coral} não levam em consideração taxas de churn, algo já levantado como problema em diversas DHTS~\cite{bamboo:usenix04}. Também não é mostrado no artigo como o sistema lida com tolerância a falhas.

Outro problema aparente é o fato de que com o uso da DSHT várias cópias do conteúdo podem existir na rede, boa parte destas podem estar desatualizadas. Este problema é amenizado com o uso de TTLs. 

Os pares baixando um conteúdo se inserem como dono deste a cada 10 segundos para diminuir a carga dos servidores. Acreditamos que este fator pode causar uma sobrecarga na overlay.

\section{Squirrel}

O projeto Squirrel\cite{squirrel} é uma solução de distribuição de caches similar ao CoralCDN, mas este foi feito para redes locais. O Squirrel difere do CoralCDN no sentido de que os clientes devem configurar manualmente um proxy inicial no seu browser. Além disso, servidores de conteúdo não fazem o uso do sistema.

O projeto aparenta ter sido abandonado, nenhuma maneira de usá-lo foi descoberta e só foram encontrados resultados de simulação.

O funcionamento do Squirrel é bem simples. Um proxy usa uma DHT (Pastry \cite{past01}) para pesquisar quem é o dono da chave (URL) daquele conteúdo. Caso este dono tenha um cache este é retornado, caso contrário o dono adquire o conteúdo da internet e retorna este conteúdo.

Existe um segundo modo de funcionamento onde o nó dono da chave não retorna o conteúdo, mas sim uma lista de outro proxies que contêm caches do conteúdo. Este nó dono conhece os proxies pois sempre que um cache é feito a informação sobre quem tem este cache é atualizado na DHT. O proxy cliente contacta um dos proxies desta lista para adquirir o conteúdo da mesma forma como foi feito no modo de funcionamento anterior.

O fato de usar Pastry pode causar diversos problemas com o sitema, pois esta DHT não funciona bem em diversos cenários \cite{bamboo:usenix04}. O sistema é simples e teoricamente resolve o problema, mas não existe maneira de utilizá-lo atualmente.

\section{YOUSERV}

YOUSERV \cite{youserv} trata-se de uma ferramenta que possibilita um usuário de uma intranet publicar seu conteúdo de maneira simples e sem grandes custos. Um usuário precisa apenas instalar o software YOUSERV para publicar conteúdo, fornecendo seu login e senha da intranet. O conteúdo é publicado e pode ser acessado através da Internet usando um browser, desde de que se tenha uma senha de acesso à intranet.

YOUSERV faz uso de uma rede P2P para publicar o conteúdo dos usuários com baixo custo
e de maneira simples. Abaixo são listadas algumas das características da ferramenta:

\begin{itemize}
 \item O usuário recebe um nome de domínio que mapeia para o seu site, onde está disponibilizado o seu conteúdo, não importando o fato do IP não ser estático.
 \item O conteúdo disponibilizado por um usuário pode ficar acessível mesmo quando este não se encontra conectado. Isso é possível fazendo uso de replicação do conteúdo.
 \item Mesmo estando atrás de um firewall é possível publicar conteúdo.
\end{itemize}

Atualmente, YOUSERV não dá suporte a pesquisa por conteúdo dinâmico.

YOUSERV faz uso de replicação para tornar o conteúdo acessível mesmo quando o provedor do conteúdo não está online. A replicação do conteúdo de um usuário é feita entre os sites que esse usuário escolhe. Este acordo deve ser feito por ambas as partes, ou seja, quando um usuário escolhe um site para replicar seu conteúdo, esse site deve aceitar a requisição.

A ferramenta faz uso de proxy para que os usuários que não estão acessíveis através da porta 80 possam disponibilizar seus conteúdo através deste proxy. O uso de muitos proxies para um site pode também ser uma técnica que possibilite balancear a carga quando um site está sobrecarregado de conexões.

O sistema é composto por 4 componentes:

\begin{itemize}
 \item Browsers - Qualquer máquina rodando um navegador e acessando o conteúdo disponibilizado.
`\item Nós - São as máquinas que devem instalar o software. São os peers da rede onde os conteúdos estão distribuídos.
 \item DNS Dinâmico - Uma entidade centralizada que faz uso do protocolo DNS para resolução dos nomes das máquinas para os respectivos IPs.
 \item Coordenador - Entidade centralizada que provê: autenticação de usuários, mapeamento das replicações e dos proxies, detecção de firewall etc. Esta entidade é o ponto de entrada da rede.
\end{itemize}

Os protocolos utilizados pela ferramenta são o HTTP e o DNS, fazendo com que não seja preciso o desenvolvimento de clientes específicos que falem os protocolos usados.

A seguir são descritos os passos necessários para que um peer publique conteúdo:

\begin{enumerate}
 \item Um usuário instala o sistema e faz login no Coordenador.
 \item O Coordenador marca o site como publicado.
 \item O Coordenador registra no DNS Dinâmico (DynDNS) o IP do peer e mapeia para o site do usuário.
\end{enumerate}

Agora, os passos para que este conteúdo seja acessado:

\begin{enumerate}
 \item Um usuário com um web browser tenta acessar um determinado site através de um nome.
 \item O DynDNS resolve o nome para o IP do peer dono do site.
 \item O browser faz uma requisição HTTP para o peer daquele site.
 \item O peer responde usando o protocolo HTTP.
\end{enumerate}

O projeto mostra-se maduro e a forma com que efetua a distribuição e acesso ao conteúdo assemelha-se à proposta do WebP2P. As técnicas utilizadas para efetuar proxing e replicação podem ser muito úteis nas decisões de nossa equipe.

No ano de 2002 existiam cerca de 3000 usuários do YOUSERV e 1200 peers espalhados pela web. O sistema estava no ar na rede interna da IBM havia nove meses. Estes números são indícios de que a ferramenta funciona de maneira satisfatória para o que se propõe. Não temos informações do estado atual da rede.

Um dos pontos a se investigar é se o YOUSERV funciona somente para computadores com acesso a determinada intranet.

\section{Browsers-Aware Proxy Server}

\cite{browsers-aware} apresenta uma proposta para diminuir o tráfego com servidores web na Internet através do uso de um proxy que indexa arquivos residentes em caches de browsers de clientes em uma rede. O trabalho também faz uma análise para concluir se a quantidade de dados compartilhados entre os clientes é significativa o bastante para se utilizar a técnica na construção de um cache Web com alta performance e que seja escalável.

O procedimento executado para um cliente obter um arquivo na Web parte de uma simples consulta ao cache local do seu navegador. Caso não encontre, um proxy é acionado e seu cache consultado. Se ainda assim o arquivo não for encontrado, antes de requisitar o arquivo ao servidor web, o proxy consulta uma tabela de índices que armazena caminhos para localização de arquivos em caches de clientes. Se encontrar, dois caminhos podem ser seguidos: (i) o cliente que possui o arquivo o envia diretamente ao usuário que fez a requisição ou (ii) o proxy baixa o arquivo do cliente e envia ao usuário que o requisitou.

Há uma preocupação com a integridade dos dados e o anonimato entre os clientes. A integridade dos dados é resolvida através do armazenamento do MD5 dos arquivos nos índices do proxy, de forma que sempre que um arquivo for modificado no cliente e um outro cliente o requisitar, a checagem no proxy irá acusar e notificar mudança de conteúdo. Já o anonimato é garantido através do procedimento indicado em (ii).

O artigo lido é datado de 2002 e ainda se encontrava em fase de desenvolvimento. Não sabemos o estado atual do mesmo. Porém a idéia e a arquitetura proposta são bastante interessantes por explorarem vários níveis de cache e obter uma otimização na busca por conteúdo web.

A forma como é implementada a segurança servirá como modelo para o WebP2P, que utilizará o esquema de chaves simétricas para comunicação entre entidades. Além disso, a indexação e checagem de integridade dos dados são funcionalidades indispensáveis ao WebP2P e certamente precisam ser consideradas.

\chapter{Tecnologias Estudadas}

Para ser feita a implementação da nossa solução, uma pesquisa foi feita abrangendo diversas tecnologias de comunicação entre processos. Foram analisadas tecnologias das mais primitivas como Sockets até tecnólogias mais sofisticadas que utilizam conceitos de chamada remota de procedimentos (RPC) \cite{rpc}. Abaixo descrevemos as tecnologias estudadas como também suas vantagens e desvantagens.

\section{Sockets}

Sockets e Datagramas são primitivas de comunicação TCP/UDP. Sockets podem ser vistos como a combinação de um endereço IP e uma porta, o sistema operacional se encarrega de associar os sockets aos processos. Os processos utilizam os sockets para se comunicarem com outros processos remotos. Sockets podem ser de dois tipos:
\begin{enumerate}
	\item Datagram Socket: Utilizado pelo protocolo UDP, envia mensagens contidas em Datagramas.
	\item Stream Socket: Utilizado pelo protocolo TCP, são orientados a conexão, tratando o envio de mensagens como um stream.
\end{enumerate}

Socket é a tecnologia de comunicação mais primitiva dentre as estudadas. Para a utilização de Sockets o formato das mensagens enviadas precisa ser definido. Por este motivo, sua utilização pode ser complexa. A confiabilidade na entrega das mensagens pode ser comprometida com o uso de Datagram Sockets. A vantagem do uso de sockets é a obtenção de um maior controle das mensagens e o baixo overhead que estes causam na aplicação.

Sockets são a base de comunicação remota entre processos e são utilizados nas outras tecnologias estudadas, mas o seu uso é transparente ao usuário.

\section{XML-RPC}

XML-RPC\cite{xml-rpc} é um protocolo simples de comunicação que utiliza mensagens HTTP para o envio de conteúdo em formato XML. O conteúdo XML das mensagens determina os procedimentos que devem ser chamados, assim como seus paramêtros e o valor de retorno.

A maior vantagem do XML-RPC é o fato deste ser independente de linguagem, assim como os sockets, mas bibliotecas são necessárias para que as linguagens possam utilizar esta tecnologia. Boa parte das linguagens já têm bibliotecas disponíveis. A sua desvantagem é o overhead para a aplicação, pois para cada mensagem um conteúdo XML tem que ser interpretado.

\section{RMI}

Remote Method Invocation (RMI)\cite{rmi} é uma forma de comunicação (usando RPC) entre processos Java\cite{java}. As bibliotecas padrões do Java já contém os pacotes necessários para o uso de RMI. Esta tecnologia provê ferramentas para que seja possível para o programador desenvolver uma aplicação sem se preocupar com detalhes de comunicação entre os diversos elementos remotos de um sistema, pois estes são vistos dentro de um programa como objetos Java.

Uma das características interessantes do RMI é o fato deste ser síncrono. Assim, ao ser feita uma chamada remota, o código só tem um retorno quando todo o trecho de código do procedimento remoto é executado. Esta característica já foi levantada como problema para alguns sistemas P2P \cite{jic-aliandro} devido ao overhead das mensagens síncronas do RMI.

O fato de ser de fácil uso é uma grande vantagem do RMI, porém somente aplicações Java podem utilizá-lo. Outros problemas já foram levantados, como o fato de que para cada chamada uma nova thread é criada podendo causar assim um grande overhead na aplicação \cite{jic-aliandro}.

\section{JIC}

Java Internet Communication (JIC)\cite{jic-aliandro} é uma alternativa ao RMI desenvolvida no Laboratório de Sistemas Distribuídos da Universidade Federal de Campina Grande (UFCG). O fato de ter um código desenvolvido na UFCG, onde o projeto WebP2P será desenvolvido, nos fornece um maior nível de suporte.

O JIC visa ser de fácil uso como o RMI mas para comunicações assíncronas. Outra vantagem é que ele possui um detector de falhas embutido e não traz o problema de explosão de threads citado na subseção anterior.

\section{JXTA}

O JXTA (do inglês juxtapose) é uma especificação independente de linguagem e plataforma para comunicação entre dispositivos sem considerar sua localização física e tecnologia de rede no qual se encontram instalados. É uma plataforma livre, tendo sido criada pela Sun Microsystems em 2001.

A plataforma JXTA foi especificada na forma de uma arquitetura microkernel, ou seja, mesmo os serviços mais básicos estão implementados como módulos, restando para o kernel propriamente dito poucas funções, em geral, de comunicação entre os próprios módulos. Portanto, serviços básicos como a descoberta de peers ou de recursos na rede, comunicação entre dois ou mais peers, entre outros, são todos providos por módulos específicos.

\subsection{Peer e Peer Group}

Uma rede virtual JXTA consiste de alguns tipos de peers, sendo que um peer conectado a rede pode, em teoria, assumir qualquer um destes papéis descritos a seguir:

\begin{itemize}
\item Edge Peers - São os peers simples, podendo tanto ser computadores desktop, conectados por uma LAN ou modem à Internet, e outros dispositivos computacionais.

\item Minimal Peers - Dispositivos com restrições de recursos, como celulares e palms, são chamados minimal peers e, geralmente, não possuem toda a funcionalidade disponível pela plataforma JXTA aos peers.

\item Proxy Peers - Peers instalados em computadores que realizam funções de proxy (para mensagens da plataforma JXTA) para minimal peers que não possuem endereço IP público; para peers que, mesmo possuindo IP, não podem realizar operações intensivas em termos de recursos computacionais; ou para peers localizados atrás de um firewall (neste caso, todas as requisições são transmitidas através de HTTP.)

\item Rendezvous Peers - Papel que costuma ser assumido por peers com maior poder computacional, com endereço IP fixo, que atuam como cache de informação (advertisements) sobre os peers conectados, facilitando a descoberta de recursos e provendo operações de resolução, tal como resolução de nome de peer para endereço IP.

\item Relay Peers - Peers que adquirem informação de roteamento, bem como realizam passagem de mensagens para outros peers atrás de um firewall, um NAT ou, simplesmente, através de roteador. Normalmente, os papéis de Rendezvous e Relay são assumidos por um mesmo peer.

\end{itemize}

Peers se organizam em grupos (Peer Groups). A especificação não define o que esses grupos são ou porque eles existem. Porém, em geral, grupos são usados para definir um conjunto de serviços e recursos, prover uma região de acesso controlado, criação de escopo, monitoração de membros, entre outras aplicações deste conceito.

\subsection{Advertisements}

Todas as entidades da plataforma JXTA, incluindo peers, groups, pipes e serviços, são representadas usando advertisements; documentos XML bem formados contendo informação à respeito dessas entidades (um metadado). Todas as entidades possuem um ID único e universal, além de informações adicionais específicas. Quando um recurso é disponibilizado na rede, na verdade, é porque seu advertisement foi criado e publicado, ou seja, enviado para os demais peers on-line.

Um advertisement possui um tempo de vida (lifetime) que visa evitar descrever entidades que já não existem na rede; uma vez que advertisements podem ser armazenados nos caches locais dos peers. A cada inicialização de um peer, os advertisements expirados são eliminados.

Note que um advertisement só existe enquanto algum peer on-line armazenar uma cópia do mesmo. Logo, o recurso associado a este advertisement só estará disponível se este também estiver.

A plataforma JXTA define seis adverstisements básicos: Peer, Peergroup, Pipe (canal virtual de comunicação ponto-a-ponto), Service (abstração para serviço oferecido por um Peer ou Peergroup), Content (abstração para conteúdo publicado) e Endpoint (pontos de conexão de um pipe).

\subsection{Pipes e Messages}

Peers transmitem mensagens apenas através de pipes, canais virtuais que são, em geral, unidirecionais e não-confiáveis, anexáveis a um ponto de entrada e outro de saída (end points). Pipes possuem IDs únicos, e não são associados a nenhum dispositivo de rede real, havendo um serviço de resolução de IDs para dispositivos de rede. Também estão disponíveis pipes bi-direcionais ou confiáveis, implementados sobre os pipes convencionais.

Mensagens são documentos XML bem formados, que possuem roteamento baseado no ID da fonte, carregando em seu cabeçalho (header) a informação de roteamento necessária, tal como a seqüência de peers a ser percorrida.

\subsection{Protocolos}

São sete os serviços básicos fornecidos pela plataforma JXTA e, a princípio, providos por qualquer peer group criado.

\begin{enumerate}
 \item \textit{Peer Discovery Protocol}

	Peers utilizam este protocolo para descobrir recursos do JXTA dinamicamente. Em uma rede IP, a implementação deste protocolo consiste de duas tarefas: o envio de uma mensagem multicast através da rede local do peer e de Rendezvous Peers para a descoberta de peers além da rede local. Este protocolo é implementado pelo Discovery Service.

	Alguns peers presentes na rede podem não responder uma mensagem de consulta a um recurso, pois o protocolo é não-confiável. Felizmente, quanto mais peers existirem na rede, mais rápida será a descoberta dos mesmos, pois quando um peer responde a consulta, ele envia todos os advertisements relacionados a mesma que ele tenha descoberto anteriormente.

	Os Rendezvous Peers são usados para armazenar advertisements de recursos que ele conhece, incluindo peers. Alguns Rendezvous são providos pela própria Sun com o objetivo de permitir a localização de Rendezvous dinâmicos, ou seja, aqueles que assumem dinamicamente este papel. Cada grupo pode, inclusive, fixar uma taxa de Rendezvous presentes, caso sirva a algum propósito específico.

 \item \textit{Peer Resolver Protocol}

	Permite o envio de uma consulta genérica a outros peers (unicast ou multicast). Este protocolo serve de infra-estrutura para outros protocolos do JXTA, tais como o Peer Information (PIP) e o Peer Discovery (PDP).

 \item \textit{Peer Information Protocol}

	Coleta informações sobre o estado de um peer, sendo útil para accounting (para consumo de serviços providos), monitoramento de desempenho da rede, execução de algoritmos que baseados em informação global, entre outras aplicações. O PIP provê uma funcionalidade de polling para checar se um dado peer está on-line, bem como solicitar o seu advertisement.

 \item \textit{Rendezvous Protocol}

	É o protocolo responsável por propagar mensagens dentro de um grupo e controlar esta propagação, bem como permitir a conexão a serviços. O RVP é base para dois outros protocolos: o Peer Resolver (PRP) e o Pipe Binding (PBP).

 \item \textit{Rendezvous Protocol}

	É o protocolo responsável por propagar mensagens dentro de um grupo e controlar esta propagação, bem como permitir a conexão a serviços. O RVP é base para dois outros protocolos: o Peer Resolver (PRP) e o Pipe Binding (PBP).

 \item \textit{Pipe Binding Protocol}

	É o protocolo responsável por conectar um pipe a seus dois endpoints. Uma mensagem de consulta é enviada pela rede para encontrar um pipe endpoint já conectado ao pipe desejado.

 \item \textit{Endpoint Routing Protocol}

	Estabelece um conjunto de mensagens de busca usadas para encontrar informações de roteamento, antes da execução do envio de uma mensagem entre peers. As rotas encontradas são armazenadas localmente, e incluem informações sobre o Peer ID do remetente, Peer ID do destinatário, o time-to-live (TTL) e a seqüência ordenada de peers na rota.

 \item \textit{Membership Protocol}

	Utilizado para serviços de validação de peers para entrada em grupos. A implementação padrão deste protocolo é precária, consistindo de uma senha única para entrada no grupo.
\end{enumerate}

\input{arquitetura}

\bibliographystyle{abbrv}
\bibliography{bibs}

\chapter{Metodologia}

\section{Aquisição do embasamento teórico}

Por se tratar de um projeto voltado à pesquisa, as primeiras etapas do nosso trabalho foram dedicadas à execução de uma extensa revisão bibliográfica na qual levantamos as soluções existentes para disponibilização de conteúdo, bem como os problemas existentes nas mesmas. Essa revisão foi efetuada através da leitura de artigos tais como \cite{1,2,3,4,5 ...} e com  o intuito de galgar o embasamento teórico necessário para que pudessemos implemetar nossa solução de maneira satisfatória.

Ao longo das primeiras semanas do projeto, todos os integrantes foram responsáveis por ler um artigo e fazer o seu resumo. A cada encontro semanal, havia um seminário de nivelamento onde o responsável pelo artigo destacava pontos importantes a serem discutidos e levados em consideração para a composição da solução WebP2P. A equipe se reunia com o cliente, o professor Marco Aurélio Spohn, e discutia aspectos relevantes do artigo, além de possíveis soluções e abordagens semelhantes às estudadas. Neste cenário, o professor Marco teve o importante papel de orientador de nossa pesquisa por se tratar de um professor e que possui experiência nessa área. Instruindo-nos a efetuar um trabalho inicial de pesquisa de qualidade, nos apontando os aspectos que deveríamos focar e quais abordagens seriam interessantes de serem atacadas.

Com o fim dos seminários de nivelamento e da atividade de revisão bibliográfica, propusemos ao cliente o desenvolvimento de um simulador que modelaria o sistema e validaria a nossa solução em ambiente simulado. A idéia da implementação do simulador surgiu da dificuldade de se ter acesso a um cenário realístico que serviria de base para a validação de nossa solução. Neste caso, um simulador que executasse os dois cenários diferentes (centralizado e distribuído) facilitaria a experimentação de nossa solução, uma vez que nos permitiria controlar uma quantidade maior de parâmetros relevantes.

Além disso, a construção de um simulador nos daria uma visão mais detalhada e crítica do problema que estávamos atacando. De fato, o entendimento por parte dos integrantes em relação a técnica que adotaríamos foi sendo lapidado durante o desenvolvimento do mesmo. Ao término, pudemos chegar a um consenso em relação às abordagens que deveríamos utilizar, bem como à arquitetura a ser desenvolvida. Na seção \ref{desenvolvimento_simulador} descrevemos em detalhes como se deu o desenvolvimento do simulador.

\section{Desenvolvimento do Simulador}
\label{desenvolvimento_simulador}
O desenvolvimento do simulador se deu durante o período da disciplina Projeto 1, se estendendo até parte da disciplina de Projeto 2. A equipe do nosso projeto não possuía conhecimentos aprofundados em simulação, tendo por esse motivo que buscar referências em livros como \cite{performance_by_design}. O desenvolvimento deu-se utilizando algumas técnicas do processo de desenvolvimento extreme programming, dentre as principais, destacamos programação em par. Acreditamos que fazendo uso desta técnica a qualidade do código aumenta por haver uma revisão contínua e duplicada do mesmo.

Enquanto dois integrantes da equipe produziam o código, o outro procurava por uma forma de validar o simulador que estava sendo implementado. Reuniões semanais eram feitas afim de discutir a arquitetura do simulador e dividir as tarefas entre os integrantes da equipe. As abordagens e decisões tomadas nas reuniões técnicas eram discutidas com  a equipe e o cliente quinzenalmente.

Para fins de documentação, usamos uma página web para registrar as decisões tomadas nas reuniões bem como o planejamento das atividades futuras. Escolhemos o dokuwiki (http://wiki.splitbrain.org/wiki:dokuwiki) como ferramenta de suporte a edição colaborativa da página web de nosso projeto (http://www.lsd.ufcg.edu.br/\~flaviov/webp2p).

\subsection{Experimentação}
Para fins de medição da carga em um web server, usamos a ferramenta JMeter. O intuito era gerar inúmeros acessos a um servidor e ver qual o comportamento do mesmo em relação as requisições. JMeter é uma ferramenta open source que analisa o comportamento de servidores em relação a uma determinada carga de requisições. A ferramenta dá suporte ao controle de parâmetros da experimentação e gera gráficos com informações relavantes para a comparação entre servidores. No contexto do nosso projeto, analisar os gráficos relativos à apenas um servidor e compará-los com os gráficos relativos à nossa solução, seria uma forma de validar o projeto WebP2P. A figura \ref{grafico-jmeter} mostra um exemplo de gráfico gerado pela ferramenta.

\begin{figure}[htbp]
\centering
\includegraphics[width=15cm]{img/grafico-jmeter.png}
\caption{Gráfico gerado pelo JMeter}
\label{grafico-jmeter}
\end{figure}


\section{Desenvolvimento da Solução}
O desenvolvimento da solução WebP2P ocorreu, em sua maior parte, no laboratório de sistemas distribuídos (LSD). Por se tratar de uma equipe pequena, composta apenas por três integrantes, optamos por aplicar uma metodologia ágil de desenvolvimento do código. As atividades de desenvolvimento foram conduzidas usando uma adaptação do processo ágil XP (Extreme Programming). Escolhemos esta metodologia por ser de conhecimento de todos os integrantes da equipe além de possuir uma vasta documentação de suporte e ser adequada ao tamanho de nossa equipe.

Usamos o eclipse \ref{eclipse} como ambiente de desenvolvimento de nossa aplicação. Esta ferramenta é bem difundida entre os programadores e contém ínumeras características que facilitam o desenvolvimento de código fonte. Para sincronização do código produzido optamos pelo uso do SVN \cite{cvs}, um sistema de controle de versões de código fonte que provê informações das mudanças efetuadas a cada submissão de código dos programadores. O plugin Subclipse \cite{subeclipse} nos permitiu trabalhar com o SVN dentro do ambiente eclipse.

O design do código desenvolvido foi amplamente discutido antes da implementação. Quanto ao design do código, optamos por sempre aplicar os padrões de projetos descritos em \cite{gamma-gof}

Diagramas de classes e figuras descrevendo a arquitetura foram gerados para que a implementação do código não entrasse em conflito com o especificado previamente nas reuniões técnicas. A Figura \ref{figura-arquitetura} e a Figura \ref{diagrama-de-classes} são exemplos dos artefatos. O uso dessas figuras foram úteis para manter a conformidade do código com o que era decidido nas reuniões.

Pela documentação do código, ficou responsável o programador que o desenvolvia. Utilizamos javadoc para descrever o funcionamento dos principais métodos do sistema.

Um aspecto importante do nosso sistema é o uso de arquivos de configuração. Esta técnica visa não manter parâmetros de configurações dentro do código fonte da aplicação. Desta maneira, quem for usar o sistema pode alterar os parâmetros sem ter que alterar o código fonte. Fizemos uso de arquivos denominados properties.

\subsubsection{Testes e Depuração}
Desde o princípio da atividade de desenvolvimento do código do WebP2P foram sendo construídos testes de unidade com o apoio do framework JUnit \cite{junit}. Por muitas vezes, mas não em sua totalidade, adotamos a técnica desenvolvimento dirigido a testes.

Por ser distribuída, a nossa solução se mostrava difícil de ser testada fazendo apenas uso do framework JUnit. Testar uma simples funcionalidade de uma classe se tornava uma tarefa laboriosa, visto que o componente a ser testados dependia de troca de mensagens com outras entidades do software. Afim de isolar as entidades a serem testadas, fizemos uso da técnica Mock. Esta abordagem visa isolar a entidade a ser testada com o intuito de focar somente em seu funcionamento. Para aplicar a técnica Mock optamos pela biblioteca EasyMock que disponibiliza métodos de criação de mokcs para classes e interfaces.

A depuração do sistema foi feita através de registro de eventos durante a execução do sistema. Para tanto, foi usado o Log4J \cite{log4j}, uma API que faz parte do projeto Jakarta de código aberto (Open Source) que tem como objetivo permitir ao desenvolvedor fazer logging em suas aplicações. Ela permite ao desenvolvedor controlar, de maneira flexível, cada saída de log apenas editando um arquivo de configuração. Como características deste framework podemos citar a flexibilidade e rapidez de geração de logging em tempo de execução, sem inserir grandes custos de performance para a aplicação.

Testes de unidade combinados com a depuração permitiu a equipe seguir o desenvolvimento do sistema com confiança no código já desenvolvido. A cada funcionalidade adicionada, todos os testes eram novamente executados para assegurar que não foram introduzidas faltas no código da aplicação.

\subsubsection{Automatização de tarefas}

Ao longo do desenvolvimento, algumas atividades eram repetidas com grande frequência, entre elas, colocar o sistema no ar e experimentá-lo, analisar logs do sistema e gerar gráficos a partir deles etc. Essas tarefas possuem passos bem definidos para a sua execução. Desta maneira, usamos a linguagem Bash para a construção de scripts que automatizam as tarefas que se repetiam com maior frequência. Esta linguagem foi escolhida pois todos os integrantes são familiarizados com sistemas Unix e possuem conhecimento da lingaguem e de suas características.

Além disso, integrado ao eclipse, usamos o projeto apache ant \cite{ant} para automatizar as tarefas de geração de \textit{deliverables} como arquivos jar, war e javadoc. Esta ferramenta é semalhante ao make, ou seja, tem por objetivo automatizar tarefas durante a construção do software. No entanto, o ant usa um arquivo xml para especificar as tarefas. Esta característica torna a ferramenta mais portável que o make, uma vez que arquivos xml são padronizados. Os arquivos usados pelo make, por sua vez, usam comandos de sistemas operacionais específicos, fato este que diminui sua portabilidade.

\subsubsection{Escrita de Relatórios}

A escrita desta monografia, além dos relatórios parciais gerados durante a disciplina de projeto 1, foi feita em latex, usando o Kile \cite{kile} como ferramenta de edição. Latex é um sistema de tipografia de documentos baseado em comandos e adequado para a construção de documentos científicos, constituídos de fórmulas matemáticas etc. Para a nossa equipe, o grande trunfo de usar o latex foi não se preocupar com a formatação do texto e sim com o seu conteúdo. Usando um estilo pré-definido, bastou apenas escrever o conteúdo do documento e gerar o arquivo. Todas as formatações necessárias são efetuadas pelo estilo que usamos.

A atividade de escrita foi desenvolvida não só no encerramento do projeto. Ela estendeu-se durante todo o andamento do cronograma. Por este fato, foi necessário controlar as várias versões produzidas ao longo do projeto fazendo uso do SVN. Este, foi importante também para manter as versões em sincronia, visto que a escrita era efetuada por todos os membros da equipe paralelamente e concomitantemente.

Uma das atividades que impactaram de forma muito positiva na escrita foi a revisão bibliográfica. O embasamento que esta atividade nos deu, permitiu que escrevessemos com propriedade sobre o problema abordado e a solução que propusemos. A busca por trabalhos relacionados e o levantamento do estado da arte nos proporcionou o conhecimento desejável para que a escrita refletisse todos os aspectos englobados pelo projeto.
\end{document}